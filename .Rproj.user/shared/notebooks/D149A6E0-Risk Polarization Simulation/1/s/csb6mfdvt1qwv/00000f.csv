"0",""
"0","#shape our population dataframe so it is easier to work with, as well as turn values to numeric, so we can start with calculations"
"0","df <- t(df)"
"0","colnames(df) <- NULL"
"0","df <- mutate_all(as.data.frame(df), as.numeric)"
"0","df <- t(df)"
"0",""
"0","#round our matrix to a certain digit, so we have some ""discrete"" numbers, which makes it comparable to our study"
"0","result[,-c(1:2)] <- round(result[,-c(1:2)], digits = 2)"
"0",""
"0",""
"0","#creating the functions for our polarizatino measurements"
"0",""
"0","calc_dispersion <- function(vec){"
"0","      median_val <- median(vec, na.rm = TRUE)"
"0","      abs_deviation <-  abs(vec - median_val)"
"0","      return(median(abs_deviation, na.rm = TRUE))"
"0","}"
"0",""
"0","calc_coverage <- function(vec, range = 1, n_intervals = 10){"
"0",""
"0","   intervals <- range/n_intervals * c(0:n_intervals)"
"0","   to_sum <- 0"
"0","   N <-  sum(!is.na(vec))"
"0","   # Create 10 intervals for each row"
"0","   # coverages <- sapply(seq_along(intervals), function(j) {"
"0","   #    row_interval <- intervals[j]"
"0","   #    count <- sum(intervals[j] <= vec & vec <= intervals[j+1], na.rm = T)"
"0","   # }"
"0","   # )"
"0","   "
"0","   coverages <- vec %>% "
"0","      as.numeric() %>% "
"0","      cut(breaks = intervals, include.lowest = TRUE) %>% "
"0","      table() %>% "
"0","      as.numeric()"
"0","   "
"0","   if (sum(coverages, na.rm = TRUE) != N){"
"0","      return(""sum of coverages not equal N"")"
"0","   }"
"0","   else{"
"0","      for (j in 1:length(coverages)){"
"0","         n <- coverages[j]"
"0","         to_sum <- to_sum + (n * (n-1))"
"0","      } "
"0","   }"
"0","   return( 1- (to_sum / (N * (N-1))) )"
"0","}"
"0",""
"0","calc_size_parity <- function(vec, midpoint = .5){"
"0","   Nhigh <- sum(vec >= midpoint, na.rm = TRUE)"
"0","   Nlow <- sum(vec < midpoint, na.rm = TRUE)"
"0","   N <- sum(!is.na(vec))"
"0","   return(abs( (Nhigh/N) - (Nlow/N)))"
"0","}"
"0",""
"0","calc_group_divergence <- function(vec, midpoint = .5, scale_range = 1){"
"0","   "
"0","   X_high <- mean(vec[vec >= midpoint], na.rm = TRUE)"
"0","   if(sum(vec[vec >= midpoint], na.rm =T ) == 0){"
"0","      X_high <- 0"
"0","   }"
"0","   "
"0","   X_low <-  mean(vec[vec < midpoint], na.rm = TRUE)"
"0","   if(sum(vec[vec < midpoint], na.rm =T ) == 0){"
"0","      X_low <- 0"
"0","   }"
"0","   return((abs(X_high - X_low)/ scale_range))"
"0","}"
"0",""
"0","calc_polarization_index <- function(vec){"
"0","   S <- calc_size_parity(vec)"
"0","   d <- calc_group_divergence(vec)"
"0","   return( (1-S)* d)"
"0","}"
"0",""
"0","calc_bimodality_coefficient <- function(vec){"
"0","   skew <- skew(vec, na.rm = TRUE, type = 3)"
"0","   kurtosis <- kurtosi(vec, na.rm = TRUE, type = 3)"
"0","   n <- sum(!is.na(vec))"
"0","   return((skew^2+1) / (kurtosis + ((3*((n-1))^2)/((n-2)*(n-3))) ))"
"0","}"
"0",""
"0",""
"0","#needed for the polarization measure"
"0","calc_ordered_freq_vec <- function(vec, range = 1, n_intervals = 100){"
"0","   "
"0","   intervals <- range/n_intervals * c(0:n_intervals)"
"0","   N <- sum(!is.na(vec))"
"0","   #get ordered frequency vector, which is needed for the main function, but foreach and dopar does not support pipes, so I'll have to write it in base R syntax..."
"0","   ordered_freq_vec <-"
"0","      as.numeric(table(cut(as.numeric(vec), breaks = intervals, include.lowest = TRUE)))"
"0","   "
"0","   if (sum(ordered_freq_vec, na.rm = TRUE) != N){"
"0","      return(""sum of coverages not equal N"")"
"0","   }"
"0","   return(ordered_freq_vec)"
"0","}"
"0",""
"0",""
"0","# calculate our measures on our samples, as well as on our population "
"0","dispersion_result <- apply(result[,-(1:2)], 1, calc_dispersion)"
"0","sum(is.na(dispersion_result))"
"1","[1]"
"1"," 0"
"1","
"
"0","coverage_result <- apply(result[,-(1:2)], 1, calc_coverage)"
"0","coverage_result2 <- as.integer(coverage_result)"
"0","sum(is.na(coverage_result))"
"1","[1]"
"1"," 0"
"1","
"
"0","size_parity_result <- apply(result[,-(1:2)], 1, calc_size_parity)"
"0","sum(is.na(size_parity_result))"
"1","[1]"
"1"," 0"
"1","
"
"0","group_divergence_result <- apply(result[,-(1:2)], 1, calc_group_divergence)"
"0","sum(is.na(group_divergence_result))"
"1","[1]"
"1"," 0"
"1","
"
"0","polarization_index_result <- apply(result[,-(1:2)], 1, calc_polarization_index)"
"0","sum(is.na(polarization_index_result))"
"1","[1]"
"1"," 0"
"1","
"
"0","BC_result <- apply(result[,-(1:2)], 1, calc_bimodality_coefficient)"
"0","sum(is.na(BC_result))"
"1","[1]"
"1"," 0"
"1","
"
"0","#as the computation of polarisation is really straining with 100 categories, this took around 30 min to compute, even with 6 cores and what I believe to be the most efficient way possible to calculate. For this reason, I've saved the results to a sepparate RDS file so it is easier to get acess to it without recalculating this polarisation measure again."
"0",""
"0","# cl <- makeCluster(detectCores())"
"0","# registerDoParallel(cl)"
"0","# "
"0","# freq_vec_results <- foreach(i = 1:nrow(result), .combine = rbind) %dopar% {"
"0","#   calc_ordered_freq_vec(result[i, -c(1:2)])"
"0","# }"
"0","# "
"0","# "
"0","# polarization_result <- foreach(i = 1:nrow(freq_vec_results), .combine = c) %dopar% {"
"0","#   agrmt::polarization(freq_vec_results[i, ])"
"0","# }"
"0","# "
"0","#saveRDS(polarization_result, ""polarisation_result.rds"")"
"0","# "
"0","# "
"0","# #polarization_result <- foreach(i = 1:nrow(result), result[,-(1:2)], 1, calc_polarization)"
"0","# stopCluster(cl)"
"0",""
"0",""
"0",""
"0",""
"0","polarization_result <- readRDS(""polarisation_result.rds"")"
"0","sum(is.na(polarization_result))"
"1","[1]"
"1"," 0"
"1","
"
"0","combined_result_measures <- cbind(polarization_result, "
"0","                                  dispersion_result,"
"0","                                  coverage_result,"
"0","                                  size_parity_result,"
"0","                                  group_divergence_result,"
"0","                                  polarization_index_result,"
"0","                                  BC_result,"
"0","                                  result[,1:2]"
"0","                                  )"
"0",""
"0","sum(is.na(combined_result_measures))"
"1","[1]"
"1"," 0"
"1","
"
"0","vis_miss(combined_result_measures, sort_miss = F)"
